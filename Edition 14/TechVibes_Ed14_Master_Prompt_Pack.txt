Tech Vibes with Shaphy — Edition 14
Master Prompt Pack: Industry-Specific Research + Risk Reviews for AI Decision Systems (2026)

Purpose
- Help founders, product leaders, compliance teams, AI builders, and enterprise buyers run repeatable, defensible risk reviews.
- This is NOT legal advice. Use for product design, procurement diligence, and workflow controls.

How to use (3 steps)
1) Paste the MASTER SYSTEM PROMPT once as your System instruction.
2) For each feature/workflow, paste the INDUSTRY RESEARCH INTAKE PROMPT.
3) Append ONE SECTOR ADD-ON. Then run: VULNERABILITY MATRIX → RED-TEAM → AUDIT PACKET → PROCUREMENT → EXEC MEMO.

Key lens (use every time)
- Focus on consequential decisions: hire/deny, approve/deny, eligibility, access, pricing, ranking, authorization.
- Separate: Assistive AI vs Evaluative AI vs Autonomous AI.
- Liability follows workflow impact and contestability, not “AI assist” wording or disclaimers.

-------------------------------------------------------------------------------

A) MASTER SYSTEM PROMPT (paste once)

You are an operator-grade AI Risk Research & Review agent (2026).

Your job:
Translate AI litigation/regulatory exposure into decision clarity and workflow design requirements.
This is NOT legal advice. You do not practice law.
You produce: risk hypotheses, research directions, architectural controls, auditability requirements, and procurement questions.

Operating principles:
- Focus on consequential decisions (hire/deny, approve/deny, eligibility, access, pricing, ranking).
- Liability follows impact and workflow behavior, not model choice or disclaimers.
- Prefer inspectability: contestability, audit trails, human accountability, and scoped outputs.
- Separate: Assistive AI vs Evaluative AI vs Autonomous AI.
- Be specific, not fear-driven.

Hard rules:
- If you are uncertain, say what is unknown and what evidence would resolve it.
- Do not invent case facts. If you cite cases/regulators, provide source links when available.
- No hype. No moralizing. No generic compliance fluff.

Output format (always):
1) Executive Risk Snapshot (5–8 bullets)
2) Decision System Map (inputs → model/rules → outputs → human action → outcome)
3) Exposure Surface (what could trigger claims, audits, procurement blocks)
4) Applicable Regimes to research (by jurisdiction + domain)
5) Likely Failure Modes (architecture patterns that break under scrutiny)
6) Controls & Guardrails (product + process)
7) Audit Packet Spec (what must be loggable/exportable per decision)
8) Procurement / Vendor Questions (enterprise-ready)
9) Metrics that matter (operational, not vanity)
10) Open Questions & Next Research (tight list)

-------------------------------------------------------------------------------

B) INDUSTRY RESEARCH INTAKE PROMPT (paste per workflow)

Run an industry-specific AI risk review.

Industry / domain:
Geography / jurisdictions (US states, EU, UK, etc.):
Company type (startup/enterprise, B2B/B2C, regulated/non-regulated):
Product + feature description (plain English):
What decisions does it influence? (hire/deny/approve/deny/rank/route/price/authorize):
Users impacted (employees/applicants/patients/tenants/borrowers/students/customers):
AI category (Assistive / Evaluative / Autonomous):
Human-in-the-loop (where exactly? how enforced?):
Data used (sources + sensitive/proxy risks):
Persistence (one-time vs ongoing profile / score):
Explainability given to affected people (what they see):
Contestability (how can a person dispute?):
Auditability today (what is logged/exportable?):
Vendors involved (model providers, scoring vendors, data brokers):
Deployment (SaaS, on-prem, embedded, agent actions):
Business dependency (revenue tied to this workflow):

Now produce the 10-section output format.
Prioritize: workflow behavior, contestability, audit trails, and buyer-ready requirements.

-------------------------------------------------------------------------------

C) SECTOR ADD-ON PROMPTS (append ONE)

C1) Hiring / HR / Recruiting

Sector add-on: Hiring / HR.

Extra focus:
- Applicant scoring, ranking, auto-disposition, interview automation, “fit” labels
- Proxy risks (school, zip, employment gaps, names, language, tenure, social signals)
- Adverse action, notice, and dispute workflows where applicable
- Vendor responsibility boundaries in multi-vendor hiring stacks

Include:
- A “Do Not Ship” list for high-risk hiring features without controls
- A minimum viable contestability + audit trail design for hiring outcomes
- A procurement checklist for enterprise HR buyers

---

C2) Housing / Tenant Screening

Sector add-on: Housing / tenant screening.

Extra focus:
- Eligibility scoring, fraud/risk labels, eviction/credit inputs, rental denial explanations
- Consumer-reporting-like behavior and dispute pathways
- Reason codes that map to contestable factors

Include:
- How to design dispute + correction loops operationally
- What an audit packet must contain for a denial

---

C3) Healthcare / Benefits / Prior Authorization

Sector add-on: Healthcare / benefits.

Extra focus:
- Denial automation, prior authorization routing, claims adjudication assistance
- Clinical accountability boundaries (what only clinicians can decide)
- Patient harm + timing + transparency requirements

Include:
- A “separate recommendation from denial” architecture pattern
- Monitoring + escalation design (when outputs drift)

---

C4) Lending / Credit / Fintech

Sector add-on: Lending / credit.

Extra focus:
- Eligibility decisions, pricing decisions, underwriting features
- Explainability and adverse action style requirements
- Fairness monitoring across protected classes and proxies

Include:
- Minimal explainability standard that is operational (not academic)
- Feature governance and model change control requirements

---

C5) Pricing / Marketplaces / Revenue Management

Sector add-on: Pricing systems.

Extra focus:
- Shared pricing infrastructure, competitor data pooling, recommendation uniformity
- Coordination risk hypotheses (hub-and-spoke patterns)
- Auditability of human overrides and rationale

Include:
- A governance pattern: approval gates, rationale logging, override audits

---

C6) AdTech / Matching / Delivery Systems

Sector add-on: Ad delivery / ranking systems.

Extra focus:
- Delivery outcomes (who sees what), not just targeting settings
- Outcome disparity monitoring and explainable controls
- Data provenance and experimentation guardrails

Include:
- A monitoring spec for delivery disparity + remediation workflow

-------------------------------------------------------------------------------

D) AI VULNERABILITY MATRIX CLASSIFIER (fast gate before building)

Classify this feature using an AI Vulnerability Matrix.

Feature:
Decision impacted:
AI category (Assistive/Evaluative/Autonomous):
Who is harmed if wrong:
Is there an adverse outcome (deny/reject/price increase/access removal):
Can the person contest it in-product:
Can we export an audit packet for one decision in <10 minutes:
Is there persistent profiling across contexts:
Is the human review meaningful and enforced:

Output:
- Classification: Low / Medium / High vulnerability
- Why (3 bullets)
- What must change to reduce vulnerability (5 bullets)
- “Ship/Don’t ship” recommendation with conditions

-------------------------------------------------------------------------------

E) RED-TEAM PROMPT (simulate regulator + plaintiff + enterprise buyer)

Red-team this AI workflow like a regulator, plaintiff’s attorney, and enterprise buyer.

Workflow description:
Inputs:
Outputs:
Decision impact:
Human-in-the-loop:
Logging today:

Find:
- 10 ways this could create unlawful discrimination or unfairness via proxies
- 10 ways contestability fails (people can’t see/understand/challenge outcomes)
- 10 ways auditability fails (can’t reconstruct decision path)
- 10 ways “AI assist” becomes de facto automated decision-making
- 5 high-risk UI/UX patterns (default accept, one-click reject, hidden scores)

Then produce:
- A prioritized fix list (P0/P1/P2)
- The minimum viable controls to ship safely

-------------------------------------------------------------------------------

F) AUDIT PACKET SPEC (defensibility backbone)

Design an “Audit Packet” for a single consequential decision.

Decision type:
Industry:
Jurisdiction:
Workflow steps:
Systems involved:

Output:
- Required fields for reconstruction (inputs, transformations, model/rule version, output, reviewer, final action)
- Evidence of human accountability (what proves review was meaningful)
- Explanation payload for the affected person (reason codes + plain language)
- Contestability workflow (how disputes are logged, triaged, resolved)
- Data provenance + authorization notes
- Export format (PDF/JSON) and time-to-generate target
- Retention and access controls (who can see what)

-------------------------------------------------------------------------------

G) VENDOR / PROCUREMENT DUE DILIGENCE (turn claims into artifacts)

Generate an enterprise procurement checklist for this AI system.

System description:
Industry:
AI category (Assistive/Evaluative/Autonomous):
Jurisdiction:

Output:
- 20 vendor questions grouped by: data provenance, model governance, fairness testing, explainability, auditability, HITL enforcement, incident response, and subcontractors
- Required artifacts to request (examples: test reports, change logs, logging schema, audit packet demo)
- “Dealbreaker” list (10 items)
- Contract clauses to flag for legal review (not drafting clauses; just what to look for)

-------------------------------------------------------------------------------

H) EXECUTIVE MEMO (founder / board ready)

Write a one-page executive memo on AI decision-system exposure.

Inputs:
- product/workflow description
- industry + jurisdiction
- dependency on this feature for revenue
- known gaps (contestability, audit trails, HITL enforcement)

Output:
- What’s at risk (business terms, not legal jargon)
- The top 5 failure modes
- The top 5 controls we must implement
- The metric dashboard we’ll run weekly
- What we will NOT automate (clear boundary)
- Open questions for counsel / compliance review

Tone: calm, operator-grade, no fear.

-------------------------------------------------------------------------------

Sharing note (for your newsletter comments)
“I’ll add links in the comments to industry-specific case studies, plus the master prompts used to run sector-specific research and risk reviews.”
